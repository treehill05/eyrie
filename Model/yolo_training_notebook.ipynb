{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLO Person Detection Model Training\n",
        "\n",
        "This notebook trains a YOLO model for person detection and position tracking for crowd analysis.\n",
        "\n",
        "## Dataset Requirements\n",
        "- Images with people in various crowd scenarios\n",
        "- YOLO format annotations (class_id x_center y_center width height)\n",
        "- Class 0: person\n",
        "\n",
        "## Output\n",
        "- Trained YOLO model weights\n",
        "- Position data for each detected person\n",
        "- Bounding box coordinates normalized to image dimensions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install ultralytics torch torchvision opencv-python numpy matplotlib pillow\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive to access dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set dataset path (update this path to your dataset location)\n",
        "DATASET_PATH = '/content/drive/MyDrive/CrowdProject/dataset'\n",
        "\n",
        "# Verify dataset structure\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    print(f\"Dataset found at: {DATASET_PATH}\")\n",
        "    print(\"\\nDataset structure:\")\n",
        "    for root, dirs, files in os.walk(DATASET_PATH):\n",
        "        level = root.replace(DATASET_PATH, '').count(os.sep)\n",
        "        indent = ' ' * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 2 * (level + 1)\n",
        "        for file in files[:5]:  # Show first 5 files\n",
        "            print(f\"{subindent}{file}\")\n",
        "        if len(files) > 5:\n",
        "            print(f\"{subindent}... and {len(files) - 5} more files\")\n",
        "else:\n",
        "    print(f\"Dataset not found at: {DATASET_PATH}\")\n",
        "    print(\"Please upload your dataset to Google Drive and update DATASET_PATH\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create YOLO dataset configuration file\n",
        "config_content = f\"\"\"\n",
        "# YOLO Dataset Configuration for Person Detection\n",
        "path: {DATASET_PATH}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "\n",
        "# Classes\n",
        "nc: 1  # number of classes\n",
        "names: ['person']  # class names\n",
        "\"\"\"\n",
        "\n",
        "# Write config file\n",
        "config_path = '/content/dataset.yaml'\n",
        "with open(config_path, 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(f\"Dataset configuration created at: {config_path}\")\n",
        "print(\"\\nConfiguration content:\")\n",
        "print(config_content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load YOLO model (using pre-trained YOLOv8)\n",
        "model = YOLO('yolov8n.pt')  # nano version for faster training\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "results = model.train(\n",
        "    data=config_path,\n",
        "    epochs=100,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    device=device,\n",
        "    project='/content/runs/detect',\n",
        "    name='person_detection',\n",
        "    save_period=10,  # Save checkpoint every 10 epochs\n",
        "    patience=20,     # Early stopping patience\n",
        "    lr0=0.01,        # Initial learning rate\n",
        "    lrf=0.01,        # Final learning rate\n",
        "    momentum=0.937,  # SGD momentum\n",
        "    weight_decay=0.0005,  # Weight decay\n",
        "    warmup_epochs=3,      # Warmup epochs\n",
        "    warmup_momentum=0.8,  # Warmup momentum\n",
        "    warmup_bias_lr=0.1,   # Warmup bias learning rate\n",
        "    box=7.5,              # Box loss gain\n",
        "    cls=0.5,              # Class loss gain\n",
        "    dfl=1.5,              # DFL loss gain\n",
        "    augment=True,         # Enable augmentation\n",
        "    hsv_h=0.015,          # Image HSV-Hue augmentation\n",
        "    hsv_s=0.7,            # Image HSV-Saturation augmentation\n",
        "    hsv_v=0.4,            # Image HSV-Value augmentation\n",
        "    degrees=0.0,          # Image rotation (+/- deg)\n",
        "    translate=0.1,        # Image translation (+/- fraction)\n",
        "    scale=0.5,            # Image scale (+/- gain)\n",
        "    shear=0.0,            # Image shear (+/- deg)\n",
        "    perspective=0.0,      # Image perspective (+/- fraction)\n",
        "    flipud=0.0,           # Image flip up-down (probability)\n",
        "    fliplr=0.5,           # Image flip left-right (probability)\n",
        "    mosaic=1.0,           # Image mosaic (probability)\n",
        "    mixup=0.0,            # Image mixup (probability)\n",
        "    copy_paste=0.0,       # Segment copy-paste (probability)\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
